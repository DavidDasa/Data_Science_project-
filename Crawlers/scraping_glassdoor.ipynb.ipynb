{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Glassdoor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from time import sleep\n",
    "from datetime import date\n",
    "from tqdm.auto import tqdm\n",
    "from selenium import webdriver\n",
    "from pymongo import MongoClient\n",
    "from dotenv import dotenv_values\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium\n",
    "WAIT_TIME = 10\n",
    "REPEAT_TIMES = 5\n",
    "\n",
    "# Glassdoor\n",
    "STARS_CLASSES_DICT = {\n",
    "    'css-xd4dom': 1,\n",
    "    'css-18v8tui': 2,\n",
    "    'css-vl2edp': 3,\n",
    "    'css-1nuumx7': 4,\n",
    "    'css-s88v13': 5\n",
    "}\n",
    "\n",
    "V_X_DICT = {\n",
    "    'css-hcqxoa': 'high',\n",
    "    'css-1h93d4v': 'middle',\n",
    "    'css-1kiw93k': 'low',\n",
    "    'css-10xv9lv': None\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connections and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 103.0.5060\n",
      "[WDM] - Get LATEST chromedriver version for 103.0.5060 google-chrome\n",
      "[WDM] - About to download new driver from https://chromedriver.storage.googleapis.com/103.0.5060.134/chromedriver_win32.zip\n",
      "[WDM] - Driver has been saved in cache [C:\\Users\\pc_office\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134]\n"
     ]
    }
   ],
   "source": [
    "# Selenium\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add VPN or Proxy for [ip change](https://python.plainenglish.io/3-ways-to-change-your-ip-address-with-selenium-and-python-d3a48a92214e)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_to_glassdoor():\n",
    "    try:\n",
    "        elem = WebDriverWait(driver, WAIT_TIME).until(EC.presence_of_element_located((By.XPATH, '//input[contains(@id, \"sc.keyword\")]')))\n",
    "        return\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    \n",
    "    url = \"https://www.glassdoor.com/profile/login_input.htm\"\n",
    "    driver.maximize_window()\n",
    "    driver.get(url)\n",
    "    sleep(WAIT_TIME)\n",
    "    username_input = driver.find_element(By.XPATH, '//input[contains(@id, \"inlineUserEmail\")]')\n",
    "    username_input.send_keys(dotenv_values('.env')['GLASSDOOR_USERNAME'])\n",
    "    sleep(1)\n",
    "    password_input = driver.find_element(By.XPATH, '//input[contains(@id, \"inlineUserPassword\")]')\n",
    "    password_input.send_keys(dotenv_values('.env')['GLASSDOOR_PASSWORD'])\n",
    "    sleep(1)\n",
    "    login_submit_button = driver.find_element(By.XPATH, '//button[contains(@name, \"submit\")]')\n",
    "    login_submit_button.click()\n",
    "    sleep(WAIT_TIME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_company_metadata(company_name: str):\n",
    "  company_name_for_url = company_name.replace(\"&\", \"%26\").replace(\" \", \"%20\").replace(\"'\", \"%27\").replace(\",\", \"%2C\")\n",
    "  driver.get(f'https://www.glassdoor.com/Search/results.htm?keyword={company_name_for_url}')\n",
    "  company_tile_link = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH, '//a[contains(@data-test, \"company-tile\")]')))\n",
    "  company_glassdoor_page_url = company_tile_link.get_attribute(\"href\")\n",
    "  try:\n",
    "    company_tile_img = driver.find_element(By.XPATH, '//a[contains(@data-test, \"company-tile\")]/div[1]/img')\n",
    "    company_glassdoor_logo_url = company_tile_img.get_attribute(\"src\")\n",
    "  except NoSuchElementException:\n",
    "    company_glassdoor_logo_url = \"\"\n",
    "  company_tile_rating = driver.find_element(By.XPATH, '//a[contains(@data-test, \"company-tile\")]/div[1]//strong')\n",
    "  company_glassdoor_overall_rating = company_tile_rating.text.split(\" \")[0].strip()\n",
    "  company_tile_title = driver.find_element(By.XPATH, '//a[contains(@data-test, \"company-tile\")]/div[2]/h3')\n",
    "  company_glassdoor_title = company_tile_title.text.strip()\n",
    "  company_tile_sub_title = driver.find_element(By.XPATH, '//a[contains(@data-test, \"company-tile\")]/div[2]/div[1]')\n",
    "  company_tile_sub_title_list = company_tile_sub_title.text.split(\"\\n\")\n",
    "  if len(company_tile_sub_title_list) == 2:\n",
    "    company_industry = company_tile_sub_title_list[0].strip()\n",
    "    company_number_of_employees = company_tile_sub_title_list[1].strip()\n",
    "  elif len(company_tile_sub_title_list) == 1:\n",
    "    if \"Employees\" in company_tile_sub_title_list[0].strip():\n",
    "      company_industry = \"\"\n",
    "      company_number_of_employees = company_tile_sub_title_list[0].strip()\n",
    "    else:\n",
    "      company_industry = company_tile_sub_title_list[0].strip()\n",
    "      company_number_of_employees = \"\"\n",
    "  else:\n",
    "    print(\"different length of sub title at \", company_name)\n",
    "    print(company_tile_sub_title_list)\n",
    "    company_industry = \"\"\n",
    "    company_number_of_employees = \"\"\n",
    "  company_tile_location = driver.find_element(By.XPATH, '//a[contains(@data-test, \"company-tile\")]/div[2]/div[2]')\n",
    "  company_headquarters_location = company_tile_location.text.strip()\n",
    "  company_tile_reviews = driver.find_element(By.XPATH, '//a[contains(@data-test, \"company-tile\")]/div[2]/div[4]//span[1]')\n",
    "  company_reviews = company_tile_reviews.text.strip() + \" Reviews\"\n",
    "  company_tile_salaries = driver.find_element(By.XPATH, '//a[contains(@data-test, \"company-tile\")]/div[2]/div[4]//span[2]')\n",
    "  company_salaries = company_tile_salaries.text.strip() + \" Salaries\"\n",
    "  company_tile_jobs = driver.find_element(By.XPATH, '//a[contains(@data-test, \"company-tile\")]/div[2]/div[4]//span[3]')\n",
    "  company_jobs = company_tile_jobs.text.strip() + \" Jobs\"\n",
    "  return {\n",
    "    \"Company Name\": company_name,\n",
    "    \"Industry\": company_industry,\n",
    "    \"Headquarters Location\": company_headquarters_location,\n",
    "    \"Number of Employees\": company_number_of_employees,\n",
    "    \"Number of Reviews\": company_reviews,\n",
    "    \"Number of Salaries\": company_salaries,\n",
    "    \"Number of Jobs\": company_jobs,\n",
    "    \"Glassdoor Company Title\": company_glassdoor_title,\n",
    "    \"Glassdoor Overall Rating\": company_glassdoor_overall_rating,\n",
    "    \"Glassdoor Company Page URL\": company_glassdoor_page_url,\n",
    "    \"Glassdoor Company Logo URL\": company_glassdoor_logo_url,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_glassdoor_codes_by_companies_csv(csv_path: str, metadata_path: str = None):\n",
    "  login_to_glassdoor()\n",
    "  df = pd.read_csv(csv_path, encoding=\"utf-8\")\n",
    "  company_names = df[\"Company Name\"]\n",
    "  if metadata_path:\n",
    "    metadata_df = pd.read_csv(metadata_path)\n",
    "  else:\n",
    "    metadata_df = pd.DataFrame(columns=[\"Company Name\", \"Industry\", \"Headquarters Location\", \"Number of Employees\", \"Number of Reviews\", \"Number of Salaries\", \"Number of Jobs\", \"Glassdoor Company Title\", \"Glassdoor Overall Rating\", \"Glassdoor Company Page URL\", \"Glassdoor Company Logo URL\"])\n",
    "  for name in tqdm(company_names):\n",
    "    try:\n",
    "      if metadata_path and name in metadata_df[\"Company Name\"].values:\n",
    "          pass\n",
    "      else:\n",
    "        metadata_df.loc[len(metadata_df)] = fetch_company_metadata(name)\n",
    "    except Exception as e:\n",
    "      metadata_df.to_csv(f\"data/SP500_glassdoor_metadata_{str(date.today())}.csv\", index=False)\n",
    "      raise e\n",
    "    sleep(1)\n",
    "  metadata_df = metadata_df.sort_values(\"Company Name\")\n",
    "  metadata_df.to_csv(f\"data/SP500_glassdoor_metadata_{str(date.today())}.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glassdoor_reviews_url_by_company_and_page_number(company_url: str, page_number: int = 1):\n",
    "  company_name_in_url = re.search('Working-at-(.*)-EI', company_url).group(1)\n",
    "  company_id_in_url = re.search('-EI_IE(.*)\\.11', company_url).group(1)\n",
    "  if page_number > 1:\n",
    "    glassdoor_reviews_url = f\"https://www.glassdoor.com/Reviews/{company_name_in_url}-Reviews-E{company_id_in_url}_P{page_number}.htm?sort.sortType=RD&sort.ascending=true&filter.iso3Language=eng\"\n",
    "  else:\n",
    "    glassdoor_reviews_url = f\"https://www.glassdoor.com/Reviews/{company_name_in_url}-Reviews-E{company_id_in_url}.htm?sort.sortType=RD&sort.ascending=true&filter.iso3Language=eng\"\n",
    "  return glassdoor_reviews_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_reviews(company_url: str):\n",
    "  company_reviews_url = get_glassdoor_reviews_url_by_company_and_page_number(company_url)\n",
    "\n",
    "  repeat = 0\n",
    "  while repeat < REPEAT_TIMES:\n",
    "    repeat += 1\n",
    "    try:\n",
    "      driver.get(company_reviews_url)\n",
    "      sleep(WAIT_TIME)\n",
    "      pagination_footer = WebDriverWait(driver, WAIT_TIME).until(EC.presence_of_element_located((By.XPATH, '//div[contains(@data-test, \"pagination-footer-text\")]')))\n",
    "      number_of_reviews = re.search(' ([^\\s]*) Reviews', pagination_footer.text).group(1).replace(\",\", \"\").strip()\n",
    "      repeat = REPEAT_TIMES\n",
    "    except (WebDriverException, StaleElementReferenceException) as e:\n",
    "      if repeat < REPEAT_TIMES:\n",
    "        print(\"Error Message:\", e.msg)\n",
    "        print(\"Repeat:\", repeat)\n",
    "      else:\n",
    "        raise e\n",
    "\n",
    "  return int(number_of_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_review_number_for_year_in_page(company_url: str, page: int, year: int):\n",
    "  company_reviews_url = get_glassdoor_reviews_url_by_company_and_page_number(company_url, page)\n",
    "\n",
    "  repeat = 0\n",
    "  while repeat < REPEAT_TIMES:\n",
    "    repeat += 1\n",
    "    try:\n",
    "      driver.get(company_reviews_url)\n",
    "      sleep(WAIT_TIME)\n",
    "      elem = WebDriverWait(driver, WAIT_TIME).until(EC.presence_of_element_located((By.XPATH, '//div[contains(@class, \" fb_reset\") and contains(@id, \"fb-root\")]')))\n",
    "      time_spans = driver.find_elements(By.XPATH, '//ol[contains(@class, \"empReviews\")]/li//span[contains(@class, \"authorJobTitle\")]')\n",
    "      years = [int(re.search(', ([0-9]*) -', span.text).group(1)) for span in time_spans]\n",
    "      repeat = REPEAT_TIMES\n",
    "    except (WebDriverException, StaleElementReferenceException) as e:\n",
    "      if repeat < REPEAT_TIMES:\n",
    "        print(\"Error Message:\", e.msg)\n",
    "        print(\"Repeat:\", repeat)\n",
    "      else:\n",
    "        raise e  \n",
    "        \n",
    "  years_indices_lt = [i for i, y in enumerate(years) if y < year]\n",
    "  years_indices_eq = [i for i, y in enumerate(years) if y == year]\n",
    "  years_indices_gt = [i for i, y in enumerate(years) if y > year]\n",
    "\n",
    "  if len(years_indices_eq) > 0:\n",
    "    return years_indices_eq[0] + 1\n",
    "  elif len(years_indices_lt) > 0 and len(years_indices_gt) > 0:\n",
    "    return -1\n",
    "  elif len(years_indices_gt) > 0:\n",
    "    return 0\n",
    "  else: # len(years_indices_lt) > 0:\n",
    "    return 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_end_review_number_for_year_in_page(company_url: str, page: int, year: int):\n",
    "  company_reviews_url = get_glassdoor_reviews_url_by_company_and_page_number(company_url, page)\n",
    "  \n",
    "  repeat = 0\n",
    "  while repeat < REPEAT_TIMES:\n",
    "    repeat += 1\n",
    "    try:\n",
    "      driver.get(company_reviews_url)\n",
    "      sleep(WAIT_TIME)\n",
    "      elem = WebDriverWait(driver, WAIT_TIME).until(EC.presence_of_element_located((By.XPATH, '//div[contains(@class, \" fb_reset\") and contains(@id, \"fb-root\")]')))\n",
    "      time_spans = driver.find_elements(By.XPATH, '//ol[contains(@class, \"empReviews\")]/li//span[contains(@class, \"authorJobTitle\")]')\n",
    "      years = [int(re.search(', ([0-9]*) -', span.text).group(1)) for span in time_spans]\n",
    "      repeat = REPEAT_TIMES\n",
    "    except (WebDriverException, StaleElementReferenceException) as e:\n",
    "      if repeat < REPEAT_TIMES:\n",
    "        print(\"Error Message:\", e.msg)\n",
    "        print(\"Repeat:\", repeat)\n",
    "      else:\n",
    "        raise e\n",
    "  \n",
    "  years_indices_lt = [i for i, y in enumerate(years) if y < year]\n",
    "  years_indices_eq = [i for i, y in enumerate(years) if y == year]\n",
    "  years_indices_gt = [i for i, y in enumerate(years) if y > year]\n",
    "\n",
    "  if len(years_indices_eq) > 0:\n",
    "    return years_indices_eq[-1] + 1\n",
    "  elif len(years_indices_lt) > 0 and len(years_indices_gt) > 0:\n",
    "    return -1\n",
    "  elif len(years_indices_gt) > 0:\n",
    "    return 0\n",
    "  else: # len(years_indices_lt) > 0:\n",
    "    return 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_review_page_number_for_year_by_company_url(company_url: str, year: int, sp: int = None, ep: int = None):\n",
    "  login_to_glassdoor()\n",
    "  number_of_reviews = get_number_of_reviews(company_url)\n",
    "  number_of_pages = number_of_reviews//10\n",
    "  if not sp:\n",
    "    sp = 1\n",
    "  if not ep:\n",
    "    ep = number_of_pages\n",
    "  lp, mp, rp = sp, ((ep-sp)//2)+sp ,ep\n",
    "  li, mi, ri = -2, -2, -2\n",
    "  start_dict = {}\n",
    "  while lp <= rp:\n",
    "    li = get_start_review_number_for_year_in_page(company_url, lp, year) # check first page\n",
    "    # print(\"lp\", lp, \"li\" , li)\n",
    "    if li != 11:\n",
    "      start_dict[\"start_page\"], start_dict[\"start_index\"] = lp, li\n",
    "      break\n",
    "      \n",
    "    ri = get_start_review_number_for_year_in_page(company_url, rp, year) # check last page\n",
    "    # print(\"rp\", rp, \"ri\" , ri)\n",
    "    if ri != 0 and ri != 1:\n",
    "      start_dict[\"start_page\"], start_dict[\"start_index\"] = rp, ri\n",
    "      break\n",
    "\n",
    "    mi = get_start_review_number_for_year_in_page(company_url, mp, year) # check middle page\n",
    "    # print(\"mp\", mp, \"mi\" , mi)\n",
    "    if (2 <= mi and mi <= 10) or mi == -1:\n",
    "      start_dict[\"start_page\"], start_dict[\"start_index\"] = mp, mi\n",
    "      break\n",
    "    elif mi == 0:\n",
    "      lp = lp + 1\n",
    "      rp = mp - 1\n",
    "    elif mi == 1:\n",
    "      lp = lp + 1\n",
    "      rp = mp\n",
    "    else: # mi == 11\n",
    "      lp = mp + 1\n",
    "      if ri == 0:\n",
    "        rp = rp - 1\n",
    "    mp = (lp + rp)//2\n",
    "  return start_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_end_review_page_number_for_year_by_company_url(company_url: str, year: int, sp: int = None, ep: int = None):\n",
    "  login_to_glassdoor()\n",
    "  number_of_reviews = get_number_of_reviews(company_url)\n",
    "  number_of_pages = number_of_reviews//10\n",
    "  if not sp:\n",
    "    sp = 1\n",
    "  if not ep:\n",
    "    ep = number_of_pages\n",
    "  lp, mp, rp = sp, ((ep-sp)//2)+sp ,ep\n",
    "  li, mi, ri = -2, -2, -2\n",
    "  end_dict = {}\n",
    "  while lp <= rp:\n",
    "    li = get_end_review_number_for_year_in_page(company_url, lp, year) # check first page\n",
    "    # print(\"lp\", lp, \"li\" , li)\n",
    "    if li != 10 and li != 11:\n",
    "      end_dict[\"end_page\"], end_dict[\"end_index\"] = lp, li\n",
    "      break\n",
    "      \n",
    "    ri = get_end_review_number_for_year_in_page(company_url, rp, year) # check last page\n",
    "    # print(\"rp\", rp, \"ri\" , ri)\n",
    "    if ri != 0:\n",
    "      end_dict[\"end_page\"], end_dict[\"end_index\"] = rp, ri\n",
    "      break\n",
    "\n",
    "    mi = get_end_review_number_for_year_in_page(company_url, mp, year) # check middle page\n",
    "    # print(\"mp\", mp, \"mi\" , mi)\n",
    "    if (1 <= mi and mi <= 9) or mi == -1:\n",
    "      end_dict[\"end_page\"], end_dict[\"end_index\"] = mp, mi\n",
    "      break\n",
    "    elif mi == 10:\n",
    "      lp = mp \n",
    "      rp = rp - 1\n",
    "    elif mi == 11:\n",
    "      lp = mp + 1\n",
    "      rp = rp - 1\n",
    "    else: # mi == 0\n",
    "      if li == 11:\n",
    "        lp = lp + 1\n",
    "      rp = mp - 1\n",
    "    mp = (lp + rp)//2\n",
    "  return end_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_glassdoor_start_and_end_review_numbers_by_range(csv_path: str, start_year: int, end_year: int, metadata_path: str = None):\n",
    "  login_to_glassdoor()\n",
    "  df = pd.read_csv(csv_path, encoding=\"utf-8\")\n",
    "  if metadata_path:\n",
    "    metadata_df = pd.read_csv(metadata_path)\n",
    "  else:\n",
    "    metadata_df = pd.DataFrame(columns=[\"Company Name\", \"Total Number of Reviews\", \"Start Year\", \"Page of First Review\", \"Index of First Review\", \"End Year\", \"Page of Last Review\", \"Index of Last Review\", \"Number of Reviews in Time Frame\"])\n",
    "  company_names = df[\"Company Name\"]\n",
    "  glassdoor_urls = df[\"Glassdoor Company Page URL\"]\n",
    "  for url, name in zip(tqdm(glassdoor_urls), company_names):\n",
    "    try:\n",
    "      if metadata_path and name in metadata_df[\"Company Name\"].values:\n",
    "        pass\n",
    "      else:\n",
    "        total_number_of_reviews = get_number_of_reviews(url)\n",
    "        start_dict = get_start_review_page_number_for_year_by_company_url(url, start_year)\n",
    "        print(start_dict)\n",
    "        end_dict = get_end_review_page_number_for_year_by_company_url(url, end_year)\n",
    "        print(end_dict)\n",
    "        metadata_df.loc[len(metadata_df)] = {\n",
    "          \"Company Name\": name,\n",
    "          \"Total Number of Reviews\": total_number_of_reviews,\n",
    "          \"Start Year\": start_year,\n",
    "          \"Page of First Review\": start_dict[\"start_page\"],\n",
    "          \"Index of First Review\": start_dict[\"start_index\"],\n",
    "          \"End Year\": end_year,\n",
    "          \"Page of Last Review\": end_dict[\"end_page\"],\n",
    "          \"Index of Last Review\": end_dict[\"end_index\"],\n",
    "          \"Number of Reviews in Time Frame\": end_dict[\"end_page\"]*10 + end_dict[\"end_index\"] - start_dict[\"start_page\"]*10 - start_dict[\"start_index\"] + 1\n",
    "        }\n",
    "        metadata_df.to_csv(f\"data/SP500_glassdoor_metadata_{str(date.today())}.csv\", index=False)\n",
    "    except KeyboardInterrupt as e:\n",
    "      metadata_df.to_csv(f\"data/SP500_glassdoor_metadata_{str(date.today())}.csv\", index=False)\n",
    "      raise e\n",
    "    except Exception as e:\n",
    "      metadata_df.to_csv(f\"data/SP500_glassdoor_metadata_{str(date.today())}.csv\", index=False)\n",
    "      raise e\n",
    "  metadata_df = metadata_df.sort_values(\"Company Name\")\n",
    "  metadata_df.to_csv(f\"data/SP500_glassdoor_metadata_{str(date.today())}.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_glassdoor_reviews_in_page(page_url: str, company_name: str, start_index: int = 1, end_index: int = 10):\n",
    "    repeat = 0\n",
    "\n",
    "    while repeat < REPEAT_TIMES:\n",
    "        reviews_df = pd.DataFrame(columns=[\"Company Name\", \"Total Score\", \"Work/Life Balance Score\", \"Culture & Values Score\", \"Diversity & Inclusion Score\", \"Career Opportunities Score\", \"Compensation and Benefits Score\", \"Senior Management Score\", \"Current/Former Employee\", \"Employment Length\", \"Review Title\", \"Review Date\", \"Job Description\", \"Recommend Level\", \"CEO Approval Level\", \"Business Outlook Level\", \"Pros\", \"Cons\", \"Helpful Rate\"])\n",
    "        repeat += 1\n",
    "        try:\n",
    "            driver.get(page_url)\n",
    "            sleep(WAIT_TIME)\n",
    "            elem = WebDriverWait(driver, WAIT_TIME).until(EC.presence_of_element_located((By.XPATH, '//div[contains(@class, \" fb_reset\") and contains(@id, \"fb-root\")]')))\n",
    "            for i in range(start_index, end_index+1):\n",
    "                review_dict = {}\n",
    "                review_dict[\"Company Name\"] = company_name\n",
    "                total_score_div = driver.find_element(By.XPATH, f'//ol[contains(@class, \"empReviews\")]/li[{i}]//div[contains(@class, \"gdReview\")]/div[1]/div/div/div/div')\n",
    "                review_dict[\"Total Score\"] = STARS_CLASSES_DICT[total_score_div.get_attribute('class').split(\" \")[0]]\n",
    "                work_life_balance_score_divs = driver.find_elements(By.XPATH, f'//ol[contains(@class, \"empReviews\")]/li[{i}]//div[contains(@class, \"gdReview\")]/div[1]/div/div/aside/div/div/ul/li/div[contains(text(), \"Work/Life Balance\")]/following-sibling::div')\n",
    "                review_dict[\"Work/Life Balance Score\"] = STARS_CLASSES_DICT[work_life_balance_score_divs[0].get_attribute('class').split(\" \")[0]] if len(work_life_balance_score_divs) == 1 else None\n",
    "                culture_and_values_score_divs = driver.find_elements(By.XPATH, f'//ol[contains(@class, \"empReviews\")]/li[{i}]//div[contains(@class, \"gdReview\")]/div[1]/div/div/aside/div/div/ul/li/div[contains(text(), \"Culture & Values\")]/following-sibling::div')\n",
    "                review_dict[\"Culture & Values Score\"] = STARS_CLASSES_DICT[work_life_balance_score_divs[0].get_attribute('class').split(\" \")[0]] if len(work_life_balance_score_divs) == 1 else None\n",
    "                diversity_and_inclusion_score_divs = driver.find_elements(By.XPATH, f'//ol[contains(@class, \"empReviews\")]/li[{i}]//div[contains(@class, \"gdReview\")]/div[1]/div/div/aside/div/div/ul/li/div[contains(text(), \"Diversity & Inclusion\")]/following-sibling::div')\n",
    "                review_dict[\"Diversity & Inclusion Score\"] = STARS_CLASSES_DICT[diversity_and_inclusion_score_divs[0].get_attribute('class').split(\" \")[0]] if len(diversity_and_inclusion_score_divs) == 1 else None\n",
    "                career_opportunities_score_divs = driver.find_elements(By.XPATH, f'//ol[contains(@class, \"empReviews\")]/li[{i}]//div[contains(@class, \"gdReview\")]/div[1]/div/div/aside/div/div/ul/li/div[contains(text(), \"Career Opportunities\")]/following-sibling::div')\n",
    "                review_dict[\"Career Opportunities Score\"] = STARS_CLASSES_DICT[career_opportunities_score_divs[0].get_attribute('class').split(\" \")[0]] if len(career_opportunities_score_divs) == 1 else None\n",
    "                compensation_and_benefits_score_divs = driver.find_elements(By.XPATH, f'//ol[contains(@class, \"empReviews\")]/li[{i}]//div[contains(@class, \"gdReview\")]/div[1]/div/div/aside/div/div/ul/li/div[contains(text(), \"Compensation and Benefits\")]/following-sibling::div')\n",
    "                review_dict[\"Compensation and Benefits Score\"] = STARS_CLASSES_DICT[compensation_and_benefits_score_divs[0].get_attribute('class').split(\" \")[0]] if len(compensation_and_benefits_score_divs) == 1 else None\n",
    "                senior_management_score_divs = driver.find_elements(By.XPATH, f'//ol[contains(@class, \"empReviews\")]/li[{i}]//div[contains(@class, \"gdReview\")]/div[1]/div/div/aside/div/div/ul/li/div[contains(text(), \"Senior Management\")]/following-sibling::div')\n",
    "                review_dict[\"Senior Management Score\"] = STARS_CLASSES_DICT[senior_management_score_divs[0].get_attribute('class').split(\" \")[0]] if len(senior_management_score_divs) == 1 else None            \n",
    "                employment_span = driver.find_element(By.XPATH, f'//ol[contains(@class, \"empReviews\")]/li[{i}]//div[contains(@class, \"gdReview\")]/div[1]/div/span')\n",
    "                review_dict[\"Current/Former Employee\"] = employment_span.text.strip().split(\",\")[0].strip()\n",
    "                review_dict[\"Employment Length\"] = employment_span.text.strip().split(\",\")[1].strip() if len(employment_span.text.strip().split(\",\")) == 2 else None\n",
    "                title_h2 = driver.find_element(By.XPATH, f'//ol[contains(@class, \"empReviews\")]/li[{i}]//div[contains(@class, \"gdReview\")]/div[2]/div/div[1]/h2')\n",
    "                review_dict[\"Review Title\"] = title_h2.text.strip()\n",
    "                date_and_job_span = driver.find_element(By.XPATH, f'//ol[contains(@class, \"empReviews\")]/li[{i}]//div[contains(@class, \"gdReview\")]/div[2]/div/div[1]/span')\n",
    "                review_dict[\"Review Date\"] = date_and_job_span.text.strip().split(\"-\")[0].strip()\n",
    "                review_dict[\"Job Description\"] = date_and_job_span.text.strip().split(\"-\")[1].strip() if len(date_and_job_span.text.strip().split(\"-\")) == 2 and len(date_and_job_span.text.strip().split(\"-\")[1].strip()) > 0 else None\n",
    "                recommend_span = driver.find_element(By.XPATH, f'//ol[contains(@class, \"empReviews\")]/li[{i}]//div[contains(@class, \"gdReview\")]/div[2]/div/div[1]/div/div/div/span[contains(text(), \"Recommend\")]/preceding-sibling::span')\n",
    "                review_dict[\"Recommend Level\"] = V_X_DICT[recommend_span.get_attribute('class').split(\" \")[1]]\n",
    "                ceo_approval_span = driver.find_element(By.XPATH, f'//ol[contains(@class, \"empReviews\")]/li[{i}]//div[contains(@class, \"gdReview\")]/div[2]/div/div[1]/div/div/div/span[contains(text(), \"CEO Approval\")]/preceding-sibling::span')\n",
    "                review_dict[\"CEO Approval Level\"] = V_X_DICT[ceo_approval_span.get_attribute('class').split(\" \")[1]]\n",
    "                buisness_outlook_span = driver.find_element(By.XPATH, f'//ol[contains(@class, \"empReviews\")]/li[{i}]//div[contains(@class, \"gdReview\")]/div[2]/div[1]/div/div/div/div/span[contains(text(), \"Business Outlook\")]/preceding-sibling::span')\n",
    "                review_dict[\"Business Outlook Level\"] = V_X_DICT[buisness_outlook_span.get_attribute('class').split(\" \")[1]]\n",
    "                pros_span = driver.find_element(By.XPATH, f'//ol[contains(@class, \"empReviews\")]/li[{i}]//div[contains(@class, \"gdReview\")]/div[2]/div/div[2]//span[contains(@data-test, \"pros\")]')\n",
    "                review_dict[\"Pros\"] = pros_span.text.strip()\n",
    "                cons_span = driver.find_element(By.XPATH, f'//ol[contains(@class, \"empReviews\")]/li[{i}]//div[contains(@class, \"gdReview\")]/div[2]/div/div[2]//span[contains(@data-test, \"cons\")]')\n",
    "                review_dict[\"Cons\"] = cons_span.text.strip()\n",
    "                helpful_rate_div = driver.find_element(By.XPATH, f'//ol[contains(@class, \"empReviews\")]/li[{i}]//div[contains(@class, \"gdReview\")]/div[2]/div/div[2]/div[contains(@class, \"common__EiReviewDetailsStyle__socialHelpfulcontainer pt-std\")]')\n",
    "                review_dict[\"Helpful Rate\"] = int(helpful_rate_div.text.strip().split(\" \")[0]) if 'Be' not in helpful_rate_div.text.strip().split(\" \")[0] else 0\n",
    "                reviews_df.loc[len(reviews_df)] = review_dict\n",
    "\n",
    "            repeat = REPEAT_TIMES\n",
    "        except (WebDriverException, StaleElementReferenceException, NoSuchElementException, TimeoutException) as e:\n",
    "            if repeat < REPEAT_TIMES:\n",
    "                print(\"Error Message:\", e.msg)\n",
    "                print(\"Repeat:\", repeat)\n",
    "            else:\n",
    "                raise e\n",
    "                    \n",
    "    return reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_glassdoor_reviews(csv_path: str, metadata_path: str):\n",
    "    login_to_glassdoor()\n",
    "    df = pd.read_csv(csv_path)\n",
    "    metadata_df = pd.read_csv(metadata_path)\n",
    "    company_names = metadata_df[\"Company Name\"]\n",
    "    glassdoor_urls = df[df[\"Company Name\"].isin(company_names)][\"Glassdoor Company Page URL\"]\n",
    "    for url, name in zip(tqdm(glassdoor_urls), company_names):\n",
    "        temp_reviews_dfs = []\n",
    "        review_csv_path = f\"data/reviews/{name}.csv\"\n",
    "        if os.path.exists(review_csv_path):\n",
    "            reviews_df = pd.read_csv(review_csv_path)\n",
    "        else:\n",
    "            reviews_df = pd.DataFrame(columns=[\"Company Name\", \"Total Score\", \"Work/Life Balance Score\", \"Culture & Values Score\", \"Diversity & Inclusion Score\", \"Career Opportunities Score\", \"Compensation and Benefits Score\", \"Senior Management Score\", \"Current/Former Employee\", \"Employment Length\", \"Review Title\", \"Review Date\", \"Job Description\", \"Recommend Level\", \"CEO Approval Level\", \"Business Outlook Level\", \"Pros\", \"Cons\", \"Helpful Rate\"])\n",
    "        \n",
    "        start_page = metadata_df[metadata_df[\"Company Name\"] == name].reset_index(drop=True).loc[0, \"Page of First Review\"] + len(reviews_df)//10\n",
    "        start_index = metadata_df[metadata_df[\"Company Name\"] == name].reset_index(drop=True).loc[0, \"Index of First Review\"] if len(reviews_df) == 0 else len(reviews_df)%10\n",
    "        end_page = metadata_df[metadata_df[\"Company Name\"] == name].reset_index(drop=True).loc[0, \"Page of Last Review\"]\n",
    "        end_index = metadata_df[metadata_df[\"Company Name\"] == name].reset_index(drop=True).loc[0, \"Index of Last Review\"]\n",
    "        for i, page in enumerate(range(start_page, end_page+1)):\n",
    "            reviews_page_url = get_glassdoor_reviews_url_by_company_and_page_number(url, page)\n",
    "            si =  1\n",
    "            ei = 10\n",
    "            if page == start_page:\n",
    "                si = start_index\n",
    "            if page == end_page:\n",
    "                ei = end_index\n",
    "            temp_reviews_dfs.append(scrape_glassdoor_reviews_in_page(reviews_page_url, name, start_index=si, end_index=ei))\n",
    "            if i % 10 == 0:\n",
    "                reviews_df = pd.concat([reviews_df] + temp_reviews_dfs)\n",
    "                reviews_df.to_csv(review_csv_path, index=False)\n",
    "                temp_reviews_dfs = []\n",
    "\n",
    "        reviews_df = pd.concat([reviews_df] + temp_reviews_dfs)\n",
    "        reviews_df.to_csv(review_csv_path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reviews(old_dir: str, new_dir: str, years: list = ['2017', '2018', '2019']):\n",
    "    df = pd.DataFrame(columns=[\"Company Name\", \"Number of Reviews\"])\n",
    "    files = glob(os.path.join(old_dir, \"*.csv\"))\n",
    "    for f in tqdm(files):\n",
    "        company_name = '.'.join(f.split('\\\\')[-1].split('.')[0:-1]).strip()\n",
    "        company_df = pd.read_csv(f)\n",
    "        bool_series = company_df['Review Date'].apply(lambda x: x.split(',')[-1].strip()).isin(years)\n",
    "        company_df = company_df.loc[bool_series].reset_index(drop=True)\n",
    "        company_df.to_csv(os.path.join(new_dir, f\"{company_name}.csv\"), index=False)\n",
    "        df.loc[len(df)] = {'Company Name': company_name, 'Number of Reviews': len(company_df)}\n",
    "    df.to_csv('SP500_2020_reviews_metadata.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DB Utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"data/SP500_2020_components.csv\"\n",
    "META_DATA_PATH = \"data/SP500_glassdoor_metadata_2022-06-27.csv\"\n",
    "# scrape_glassdoor_codes_by_companies_csv(CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"data/SP500_2020_glassdoor_metadata.csv\"\n",
    "META_DATA_PATH = \"data/SP500_glassdoor_metadata_2022-06-27.csv\"\n",
    "# scrap_glassdoor_start_and_end_review_numbers_by_range(CSV_PATH, 2017, 2019, META_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"SP500_2020_glassdoor_metadata_part.csv\"\n",
    "META_DATA_PATH = \"SP500_2020_reviews_glassdoor_metadata_part.csv\"\n",
    "# check_reviews_metadata(CSV_PATH, META_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"data/SP500_2020_glassdoor_metadata.csv\"\n",
    "META_DATA_PATH = \"data/SP500_2020_reviews_glassdoor_metadata.csv\"\n",
    "# scrape_glassdoor_reviews(CSV_PATH, META_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25bec17e83b4710a3731be2cb26c3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OLD_DIR = \"data/reviews_raw\"\n",
    "NEW_DIR = \"data/reviews_clean\"\n",
    "# clean_reviews(OLD_DIR, NEW_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5cf5cc52e5c0f560aa7c345a47f42967bb56ea5fd57290582a3b768ecb5c3740"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
